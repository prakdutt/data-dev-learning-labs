

# **Video Analytics Using Spark Streaming**

# **Lab Overview**

Spark Streaming is a key component of Spark, a hugely successful open project in the recent years. Spark Streaming is an extension of the core Spark API that enables scalable, high-throughput, fault-tolerant stream processing of live data streams. Data can be ingested from many sources like Kafka, Flume, Twitter, or TCP sockets, and can be processed using complex algorithms expressed with high-level functions like map, reduce, join and window. Finally, processed data can be pushed out to filesystems, databases, and live dashboards.

In this lab we see how to integrate Spark Streaming and Kafka, detect a human face using OpenCV from a video streaming, and then save the results to a file in HDFS.

## **Lab Objectives**

- Learn how to integrate the SparkStreaming with Kafka
- Learn how to perform video analytic functions in a real-time stream application
- Learn how to save a file to HDFS

## **Prerequisites**

- Knowledge of Java language, Maven
- Knowledge for OpenCV face detection function
- Studied platform user guide
- Basic knowledge of how Spark Streaming works
- Use Chrome Browser


## Step 1: Explore DLP Platform

DLP website URL ([link](https://developer.cisco.com/))

[http://10.10.10.74/DDPDevUI/demo/#/ddp/login]

1. In DLP website, go to the development area by clicking <b>"Development Hub"</b>. 
2. Select the workspace called "wksp-video-lab" and Click on <b>"Launch"</b> button.
3. It will open a new browser tab with pre-loaded video streaming code.

![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/video-analytics-spark-streaming/assets/WelComeScreenVideoStreaming.PNG?raw=true)

![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/video-analytics-spark-streaming/assets/VideoStreamingCodeInEditor.PNG?raw=true)
N.B: This sample code can be used for exploring the process.


## **Step 2: Sample Code for Detecing face from live Stream Camera attached with your workstation.
<b>N.B: Our video streaming progam is used to detect the video streaming from a source. Below Java Program is used to detect the video stream from Camera and detect the face and save the image of the face in HDFS.</b>

```json

package DDP.VideoLabs;

import java.io.BufferedInputStream;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.net.URI;
import java.security.PrivilegedExceptionAction;
import java.util.Arrays;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Random;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.function.Function;
import org.apache.spark.streaming.Durations;
import org.apache.spark.streaming.api.java.JavaDStream;
import org.apache.spark.streaming.api.java.JavaPairInputDStream;
import org.apache.spark.streaming.api.java.JavaStreamingContext;
import org.apache.spark.streaming.kafka.KafkaUtils;

import org.opencv.core.Core;
import org.opencv.core.Mat;
import org.opencv.core.MatOfRect;
import org.opencv.core.Point;
import org.opencv.core.Rect;
import org.opencv.core.Scalar;
import org.opencv.core.Size;
import org.opencv.imgcodecs.Imgcodecs;
import org.opencv.imgproc.Imgproc;
import org.opencv.objdetect.CascadeClassifier;

import kafka.serializer.DefaultDecoder;
import kafka.serializer.StringDecoder;
import scala.Tuple2;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IOUtils;
import org.apache.hadoop.security.UserGroupInformation;

public class App 
{
    public static void main( String[] args ) throws InterruptedException
    {
    	if (args.length != 3)
    	{
    		System.out.println("please set parameter value for kafka and topic and username");
    		return;
    	}
    	String kafka = args[0];
        String topics = args[1];
        final String username = args[2];
        
      	// Create context with a 2 seconds batch interval
        SparkConf sparkConf = new SparkConf().setAppName("JavaVideoLabs");
        final JavaStreamingContext jssc = new JavaStreamingContext(sparkConf, Durations.seconds(2));

        HashSet<String> topicsSet = new HashSet<String>(Arrays.asList(topics.split(",")));
        HashMap<String, String> kafkaParams = new HashMap<String, String>();
        kafkaParams.put("metadata.broker.list", kafka);
        kafkaParams.put("group.id", "groupid");
        kafkaParams.put("consumer.id", "consumerid");

        // Create direct kafka stream with brokers and topics
        JavaPairInputDStream<String, byte[]> messages = KafkaUtils.createDirectStream(
                jssc,
                String.class,
                byte[].class,
                StringDecoder.class,
                DefaultDecoder.class,
                kafkaParams,
                topicsSet
        );
        
    
           
        JavaDStream<String> content = messages.map(new Function<Tuple2<String, byte[]>, String>() {
           	private static final long serialVersionUID = 1L;
			//@Override
            public String call(Tuple2<String, byte[]> tuple2) throws IOException {
                System.loadLibrary(Core.NATIVE_LIBRARY_NAME);
                if ((tuple2 == null) || (tuple2._2().length < 1000))
                	return "";
                
                Mat image = new Mat(new Size(640, 480), 16);
                image.put(0, 0, tuple2._2()); 
                                    
                // Detect faces in the image.
                Mat mGrey = new Mat();
                Imgproc.cvtColor( image, mGrey, Imgproc.COLOR_BGR2GRAY); 
                CascadeClassifier faceDetector =
                        new CascadeClassifier(GetResourceFilePath("/haarcascade_frontalface_alt.xml").toString());
                MatOfRect faceDetections = new MatOfRect();
                faceDetector.detectMultiScale(mGrey, faceDetections);
                int len = faceDetections.toArray().length;
                System.out.println(String.format("Detected %s faces", len));
                // Draw a bounding box around each face.
                if (len > 0)
                {
	             //   SaveImageToHDFS(image, username);
	                return "face";
	              
                } else
                    return "";
           
            }
        });
    
        content.count().print();
       
        // Start the computation
        jssc.start();
        Thread.sleep(10000);
        jssc.stop();
        jssc.awaitTermination();
    }
    
    public static void SaveImageToHDFS(Mat img, String username) throws IOException
    {
    	 Random r = new Random();
    	 String tmpFile = "/tmp/" + r.nextInt(2000) + ".jpg";
         Imgcodecs.imwrite(tmpFile, img);
         String hdfsAddr = "hdfs://172.16.1.11/ddp/"+username+"/face.jpg";
         Configuration config = new Configuration();
         FileSystem fs = FileSystem.get(URI.create(hdfsAddr), config);
         Path path = new Path(hdfsAddr);
         FSDataOutputStream out = fs.create(path);
         InputStream is = new BufferedInputStream(new FileInputStream(tmpFile));
         IOUtils.copyBytes(is, out, config);
         is.close();
         out.close();
         fs.close();
         
         File f = new File(tmpFile);
     	 if (f.exists() && !f.isDirectory())
     		f.delete();
         System.out.println("write file to hdfs");
    }
    
    public static String GetResourceFilePath(String filename) {
        InputStream inputStream = null;
        OutputStream outputStream = null;
        String tempFilename = "/tmp" + filename;
        try {
        	File f = new File(tempFilename);
        	if (f.exists() && !f.isDirectory())
        		return tempFilename;
        	
            // read this file into InputStream
            inputStream = App.class.getResourceAsStream(filename);
            if (inputStream == null)
                System.out.println("empty streaming");
            // write the inputStream to a FileOutputStream
            outputStream =
                    new FileOutputStream(tempFilename);

            int read;
            byte[] bytes = new byte[102400];

            while ((read = inputStream.read(bytes)) != -1) {
                outputStream.write(bytes, 0, read);
//                System.out.println("read bytes is " + Integer.toString(read));
            }
            outputStream.flush();

            System.out.println("Load XML file, Done!");

        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            if (inputStream != null) {
                try {
                    inputStream.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
            if (outputStream != null) {
                try {
                    // outputStream.flush();
                    outputStream.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }

            }

        }
        return tempFilename;
    }
    
}

```   

## **Step 3: Maven package and submit the spark task to Hadoop cluster.**

Once we finish the above code, we can select <b>“package”</b> in the CMD menu, and click on Blue Button

![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/video-analytics-spark-streaming/assets/BlueButton.PNG?raw=true). This will package the application.

![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/video-analytics-spark-streaming/assets/BuildProject.PNG?raw=true)

After successfull packaging, select  <b>“run”</b>  click the blue button again.

![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/video-analytics-spark-streaming/assets/runProject.PNG?raw=true)

We can submit the spark task to Hadoop using the spark-submit command. You can reference the VideoLabs project&#39;s run.sh to write the submit command. After you submit it, the task will run in Hadoop cluster.

## **Step 5: Start the Video Source in DLP**

Now you need start the video source in DLP to make the video streaming data. You can follow the below step.

1. From the DLP home page, go to the App Stack area by clicking &quot;App Stack Hub&quot;
2. Find the &quot;videotest&quot; app stack after clicking &quot;stack library&quot;
3. Start the &quot;vstream&quot; micro service in the &quot;videotest&quot; after clicking the button below in the &quot;Actions&quot;. It will show the running state.

## **Step 6: View the file which has face images in DLP**

It will make an image file which has face and save it in HDFS. You can view it in DLP follow the below step.

1. From the DLP home page, go to the Data Repository area by clicking &quot;Data Repository&quot;
2. Find the image file in the data list.
3. Select the image file, then click it, you can preview the image.  

**Input** : The video streaming data from DLP.  
**Output** : An image file which has face in HDFS, and you can preview it in DLP.  

From this we have learned how to how to integrate the SparkStreaming with Kafka and how to save the file to HDFS.

There are some more examples and exercise are available in the below mentioned link. This is for your reference.

http://spark.apache.org/docs/latest/streaming-programming-guide.html

