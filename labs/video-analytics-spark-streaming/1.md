

# **Video Analytics Using Spark Streaming**

# **Lab Overview**

Spark Streaming is a key component of Spark, a hugely successful open project in the recent years. Spark Streaming is an extension of the core Spark API that enables scalable, high-throughput, fault-tolerant stream processing of live data streams. Data can be ingested from many sources like Kafka, Flume, Twitter, or TCP sockets, and can be processed using complex algorithms expressed with high-level functions like map, reduce, join and window. Finally, processed data can be pushed out to filesystems, databases, and live dashboards.

In this lab we will integrate Spark Streaming and Kafka, detect a human face using OpenCV from a video streaming, and then save the results to a file in Hadoop environment.

![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/video-analytics-spark-streaming/assets/video-image-capturing.png?raw=true)

## **Lab Objectives**

- Learn how to integrate the SparkStreaming with Kafka
- Learn how to perform video analytic functions in a real-time stream application
- Learn how to save a file to HDFS

## **Prerequisites**

- Knowledge of Java language, Maven
- Knowledge for OpenCV face detection function
- Studied platform user guide
- Basic knowledge of how Spark Streaming works
- Use Chrome Browser


## Step 1: Explore DLP Platform

DLP website URL ([link](https://developer.cisco.com/))

[http://10.10.10.74/DDPDevUI/demo/#/ddp/login]

1. In DLP website, go to the development area by clicking <b>"Development Hub"</b>. 
2. Select the workspace called "wksp-video-lab" and Click on <b>"Launch"</b> button.
3. It will open a new browser tab with pre-loaded video streaming code.

![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/video-analytics-spark-streaming/assets/WelComeScreenVideoStreaming.PNG?raw=true)

![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/video-analytics-spark-streaming/assets/VideoStreamingCodeInEditor.PNG?raw=true)
N.B: This sample code can be used for exploring the process.


## Step 2: Sample Code for Detecting face from live Stream Camera.
<b>N.B: Our video streaming progam is used to detect the video streaming from a source. Below Java Program is used to detect the video stream from Camera and detect the face and save the image of the face in HDFS.</b>

```json

package DDP.VideoLabs;

import java.io.BufferedInputStream;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.net.URI;
import java.security.PrivilegedExceptionAction;
import java.util.Arrays;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Random;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.function.Function;
import org.apache.spark.streaming.Durations;
import org.apache.spark.streaming.api.java.JavaDStream;
import org.apache.spark.streaming.api.java.JavaPairInputDStream;
import org.apache.spark.streaming.api.java.JavaStreamingContext;
import org.apache.spark.streaming.kafka.KafkaUtils;

import org.opencv.core.Core;
import org.opencv.core.Mat;
import org.opencv.core.MatOfRect;
import org.opencv.core.Point;
import org.opencv.core.Rect;
import org.opencv.core.Scalar;
import org.opencv.core.Size;
import org.opencv.imgcodecs.Imgcodecs;
import org.opencv.imgproc.Imgproc;
import org.opencv.objdetect.CascadeClassifier;

import kafka.serializer.DefaultDecoder;
import kafka.serializer.StringDecoder;
import scala.Tuple2;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IOUtils;
import org.apache.hadoop.security.UserGroupInformation;

public class App 
{
    public static void main( String[] args ) throws InterruptedException
    {
    	if (args.length != 3)
    	{
    		System.out.println("please set parameter value for kafka and topic and username");
    		return;
    	}
    	String kafka = args[0];
        String topics = args[1];
        final String username = args[2];
        
      	// Create context with a 2 seconds batch interval
        SparkConf sparkConf = new SparkConf().setAppName("JavaVideoLabs");
        final JavaStreamingContext jssc = new JavaStreamingContext(sparkConf, Durations.seconds(2));

        HashSet<String> topicsSet = new HashSet<String>(Arrays.asList(topics.split(",")));
        HashMap<String, String> kafkaParams = new HashMap<String, String>();
        kafkaParams.put("metadata.broker.list", kafka);
        kafkaParams.put("group.id", "groupid");
        kafkaParams.put("consumer.id", "consumerid");

        // Create direct kafka stream with brokers and topics
        JavaPairInputDStream<String, byte[]> messages = KafkaUtils.createDirectStream(
                jssc,
                String.class,
                byte[].class,
                StringDecoder.class,
                DefaultDecoder.class,
                kafkaParams,
                topicsSet
        );
        
    
           
        JavaDStream<String> content = messages.map(new Function<Tuple2<String, byte[]>, String>() {
           	private static final long serialVersionUID = 1L;
			//@Override
            public String call(Tuple2<String, byte[]> tuple2) throws IOException {
                System.loadLibrary(Core.NATIVE_LIBRARY_NAME);
                if ((tuple2 == null) || (tuple2._2().length < 1000))
                	return "";
                
                Mat image = new Mat(new Size(640, 480), 16);
                image.put(0, 0, tuple2._2()); 
                                    
                // Detect faces in the image.
                Mat mGrey = new Mat();
                Imgproc.cvtColor( image, mGrey, Imgproc.COLOR_BGR2GRAY); 
                CascadeClassifier faceDetector =
                        new CascadeClassifier(GetResourceFilePath("/haarcascade_frontalface_alt.xml").toString());
                MatOfRect faceDetections = new MatOfRect();
                faceDetector.detectMultiScale(mGrey, faceDetections);
                int len = faceDetections.toArray().length;
                System.out.println(String.format("Detected %s faces", len));
                // Draw a bounding box around each face.
                if (len > 0)
                {
	             //   SaveImageToHDFS(image, username);
	                return "face";
	              
                } else
                    return "";
           
            }
        });
    
        content.count().print();
       
        // Start the computation
        jssc.start();
        Thread.sleep(10000);
        jssc.stop();
        jssc.awaitTermination();
    }
    
    public static void SaveImageToHDFS(Mat img, String username) throws IOException
    {
    	 Random r = new Random();
    	 String tmpFile = "/tmp/" + r.nextInt(2000) + ".jpg";
         Imgcodecs.imwrite(tmpFile, img);
         String hdfsAddr = "hdfs://172.16.1.11/ddp/"+username+"/face.jpg";
         Configuration config = new Configuration();
         FileSystem fs = FileSystem.get(URI.create(hdfsAddr), config);
         Path path = new Path(hdfsAddr);
         FSDataOutputStream out = fs.create(path);
         InputStream is = new BufferedInputStream(new FileInputStream(tmpFile));
         IOUtils.copyBytes(is, out, config);
         is.close();
         out.close();
         fs.close();
         
         File f = new File(tmpFile);
     	 if (f.exists() && !f.isDirectory())
     		f.delete();
         System.out.println("write file to hdfs");
    }
    
    public static String GetResourceFilePath(String filename) {
        InputStream inputStream = null;
        OutputStream outputStream = null;
        String tempFilename = "/tmp" + filename;
        try {
        	File f = new File(tempFilename);
        	if (f.exists() && !f.isDirectory())
        		return tempFilename;
        	
            // read this file into InputStream
            inputStream = App.class.getResourceAsStream(filename);
            if (inputStream == null)
                System.out.println("empty streaming");
            // write the inputStream to a FileOutputStream
            outputStream =
                    new FileOutputStream(tempFilename);

            int read;
            byte[] bytes = new byte[102400];

            while ((read = inputStream.read(bytes)) != -1) {
                outputStream.write(bytes, 0, read);
//                System.out.println("read bytes is " + Integer.toString(read));
            }
            outputStream.flush();

            System.out.println("Load XML file, Done!");

        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            if (inputStream != null) {
                try {
                    inputStream.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
            if (outputStream != null) {
                try {
                    // outputStream.flush();
                    outputStream.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }

            }

        }
        return tempFilename;
    }
    
}

```   

## Step 3: Maven package and submit the spark task to Hadoop cluster.

Once we finish the above code, we can select <b>“package”</b> in the CMD menu, and click on Blue Button ![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/video-analytics-spark-streaming/assets/BlueButton.PNG?raw=true). This will package the application.

![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/video-analytics-spark-streaming/assets/BuildProject.PNG?raw=true)

After successfull packaging, select  <b>“run”</b>  click the blue button again.

![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/video-analytics-spark-streaming/assets/runProject.PNG?raw=true)

## Step 4: Run spark task.
Submitting the spark task to Hadoop using the spark-submit command. Open the run.sh file in editor and run it by clicking on Blue button. After you submit it, the task will run in Hadoop cluster.

![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/video-analytics-spark-streaming/assets/runFromHadoopCluster.PNG?raw=true)

run.sh script code is in below
```
export PATH=$PATH:/home/user/spark-1.6.1-bin-hadoop2.6/bin:/home/user/hadoop-2.6.4/bin
export HADOOP_CONF_DIR=/home/user/conf
export HADOOP_USER_NAME=dev_1
export LD_LIBRARY_PATH=/usr/local/lib/:/usr/lib/:/usr/local/share/OpenCV/java/
spark-submit --class DDP.VideoLabs.App --master yarn --deploy-mode cluster VideoLabs/target/VideoLabs-0.0.1-SNAPSHOT-jar-with-dependencies.jar 172.16.11.7:9092 ddp_video dev_1

```
<b>Three inputs are required to change based on the requirement</b>
172.16.11.7:9092  -> Kafka Broker and Port number
ddp_video -> Kafka Topic
dev_1 -> User Id
N.B:  Above are the default details for DLP Platform.

## Step 5: View the file which has face images in DLP Platform

After executing the run.sh file successfully, image file will be generated and saved into hadoop file system. You can view it in DLP follow the below step.

1. From the DLP home page, go to the Data Repository area by clicking &quot;Data Repository&quot;
2. Find the image file in the data list.
3. Select the image file, then click it, you can preview the image.  

**Input** : The video streaming data from DLP.  
**Output** : An image file which has face in HDFS, and you can preview it in DLP.  

From this we have learned how to how to integrate the SparkStreaming with Kafka and how to save the file to HDFS.

There are some more examples and exercise are available in the below mentioned link. This is for your reference.

http://spark.apache.org/docs/latest/streaming-programming-guide.html

