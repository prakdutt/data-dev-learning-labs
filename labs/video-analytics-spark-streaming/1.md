

# **Video Analytics Using Spark Streaming**

# **Lab Overview**

Spark Streaming is a key component of Spark, a hugely successful open project in the recent years. Spark Streaming is an extension of the core Spark API that enables scalable, high-throughput, fault-tolerant stream processing of live data streams. Data can be ingested from many sources like Kafka, Flume, Twitter, or TCP sockets, and can be processed using complex algorithms expressed with high-level functions like map, reduce, join and window. Finally, processed data can be pushed out to filesystems, databases, and live dashboards.

In this lab we see how to integrate Spark Streaming and Kafka, detect a human face using OpenCV from a video streaming, and then save the results to a file in HDFS.

## **Lab Objectives**

- Learn how to integrate the SparkStreaming with Kafka
- Learn how to perform video analytic functions in a real-time stream application
- Learn how to save a file to HDFS

## **Prerequisites**

- Knowledge of Java language, Maven
- Knowledge for OpenCV face detection function
- Studied platform user guide
- Basic knowledge of how Spark Streaming works
- Use Chrome Browser


## Step 1: Explore DLP Platform

DLP website URL ([link](https://developer.cisco.com/))

[http://10.10.10.74/DDPDevUI/demo/#/ddp/login]

1. In DLP website, go to the development area by clicking <b>"Development Hub"</b>. 
2. Select the workspace called "wksp-video-lab" and Click on <b>"Launch"</b>
3. Use the browser to navigate to the Dev Center for the Collaboration technology by clicking the Launch button on created workspace.

![alt-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/video-analytics-spark-streaming/assets/WelComeScreenVideoStreaming.PNG?raw=true)




## **Step 2: Creating a new project and developing code**  

1. Go to the Workspace and select the option called &quot;Create Project&quot; and select Maven project and provide the Name and Description of the project and Click on Create.

![Figure](/posts/files/video-analytics-spark-streaming/assets/create-project.png)

2. Then right click on the java present in test and select New and in that select Java Package. Then give the package name and click on OK.
3. A new project has been created and again right click on newly created project and select New and in that Java Class. Then give the name of the class and Type of the class and Click OK. A new java class will be created with package name.

![Figure](/posts/files/video-analytics-spark-streaming/assets/new-java-class.png)
 

## **Step 3: Detect the face from video streaming and save the image to HDFS**  

Once all the above mentioned steps has been done, a new project with class name will be created. Then we can start the coding of detecting the face from video streaming and save the image to HDFS. Core code as below.


```json

package DLP.VideoLabs;

import java.io.BufferedInputStream;  
import java.io.File;  
import java.io.FileInputStream;  
import java.io.FileOutputStream;  
import java.io.IOException;  
import java.io.InputStream;  
import java.io.OutputStream;  
import java.net.URI;  
import java.util.Arrays;  
import java.util.HashMap;  
import java.util.HashSet;  
import java.util.Random;  
import org.apache.spark.SparkConf;  
import org.apache.spark.api.java.function.Function;  
import org.apache.spark.streaming.Durations;  
import org.apache.spark.streaming.api.java.JavaDStream;  
import org.apache.spark.streaming.api.java.JavaPairInputDStream;  
import org.apache.spark.streaming.api.java.JavaStreamingContext;  
import org.apache.spark.streaming.kafka.KafkaUtils;  
import org.opencv.core.Core;    
import org.opencv.core.Mat;    **import org.opencv.core.MatOfRect;  
import org.opencv.core.Point;  
import org.opencv.core.Rect;  
import org.opencv.core.Scalar;  
import org.opencv.core.Size;  
import org.opencv.imgcodecs.Imgcodecs;  
import org.opencv.imgproc.Imgproc;  
import org.opencv.objdetect.CascadeClassifier;  
import kafka.serializer.DefaultDecoder;  
import kafka.serializer.StringDecoder;  
import scala.Tuple2;  
import org.apache.hadoop.conf.Configuration;  
import org.apache.hadoop.fs.FSDataOutputStream;  
import org.apache.hadoop.fs.FileSystem;  
import org.apache.hadoop.fs.Path;  
import org.apache.hadoop.io.IOUtils;  

public class App  
{  
    public static *void** main( String[] args )  
    {
        if (args.length != 3)
            {
            System.out.println(&quot;please set parameter value for kafka and topic and hdfs file address&quot;);
             return;
            }
            String kafka = args[0];

        String topics = args[1];

        final String fileAddr = args[2];

        // Create context with a 2 seconds batch interval
        SparkConf sparkConf = **new** 
        SparkConf().setAppName(&quot;JavaVideoLabs&quot;);

        JavaStreamingContext jssc = **new** JavaStreamingContext(sparkConf, Durations.seconds(2));
        HashSet&lt;String&gt; topicsSet = **new** HashSet&lt;String&gt;(Arrays.asList(topics.split(&quot;,&quot;)));
        HashMap&lt;String, String&gt; kafkaParams = **new** HashMap&lt;String, String&gt;();
        kafkaParams.put(&quot;metadata.broker.list&quot;, kafka);
        kafkaParams.put(&quot;group.id&quot;, &quot;groupid&quot;);
        kafkaParams.put(&quot;consumer.id&quot;, &quot;consumerid&quot;);

        // Create direct kafka stream with brokers and topics
        JavaPairInputDStream&lt;String, **byte** []&gt; messages = KafkaUtils.createDirectStream(
                jssc,
                String. **class** ,
                **byte** []. **class** ,
                StringDecoder. **class** ,
                DefaultDecoder. **class** ,
                kafkaParams,
                topicsSet
        );

        JavaDStream&lt;String&gt; content = messages.map( **new** Function&lt;Tuple2&lt;String, **byte** []&gt;, String&gt;() {

            private static final long** serialVersionUID = 1L;
        
            //@Override
            public String call(Tuple2&lt;String, byte []&gt; tuple2) throws IOException {
                System.loadLibrary(Core.NATIVE\_LIBRARY\_NAME);

                if ((tuple2 == null ) || (tuple2.\_2().length &lt; 1000))
                    return* null;

                Mat image = **new** Mat( **new** Size(640, 480), 16);

                image.put(0, 0, tuple2.\_2());

                // Detect faces in the image.
                CascadeClassifier faceDetector = new CascadeClassifier(GetResourceFilePath(&quot;/haarcascade\_frontalface\_alt.xml&quot;).toString());

                MatOfRect faceDetections = **new** MatOfRect();

                faceDetector.detectMultiScale(image, faceDetections);
                **int** len = faceDetections.toArray().length;
                System.out.println(String.format(&quot;Detected %s faces&quot;, len));

                // Draw a bounding box around each face.
                **if** (len &gt; 0)
                {
                    **for** (Rect rect : faceDetections.toArray())
                    {
                        Imgproc.rectangle(image, **new** Point(rect.x, rect.y), **new** Point(rect.x + rect.width, rect.y + rect.height), **new** Scalar(0, 255, 0));
                    }
                    SaveImageToHDFS(image, fileAddr);
                    System.exit(0);
                }
                **return**** null**;
            }
        });
        content.count().print();

        // Start the computation
        jssc.start();
        jssc.awaitTermination();
    }   

//We only list the core code above, you can reference the VideoLabs project for more code.  
}
```   

## **Step 4: Maven package and submit the spark task to Hadoop cluster.**

Once we finish the below code, we can select &quot;package&quot; in the CMD menu, then click the &quot;run&quot; button, it will package the project. We can see the build successful state as the below capture image.

![Figure](/posts/files/video-analytics-spark-streaming/assets/maven-package.png)

We can submit the spark task to Hadoop using the spark-submit command. You can reference the VideoLabs project&#39;s run.sh to write the submit command. After you submit it, the task will run in Hadoop cluster.

## **Step 5: Start the Video Source in DLP**

Now you need start the video source in DLP to make the video streaming data. You can follow the below step.

1. From the DLP home page, go to the App Stack area by clicking &quot;App Stack Hub&quot;
2. Find the &quot;videotest&quot; app stack after clicking &quot;stack library&quot;
3. Start the &quot;vstream&quot; micro service in the &quot;videotest&quot; after clicking the button below in the &quot;Actions&quot;. It will show the running state.

## **Step 6: View the file which has face images in DLP**

It will make an image file which has face and save it in HDFS. You can view it in DLP follow the below step.

1. From the DLP home page, go to the Data Repository area by clicking &quot;Data Repository&quot;
2. Find the image file in the data list.
3. Select the image file, then click it, you can preview the image.  

**Input** : The video streaming data from DLP.  
**Output** : An image file which has face in HDFS, and you can preview it in DLP.  

From this we have learned how to how to integrate the SparkStreaming with Kafka and how to save the file to HDFS.

There are some more examples and exercise are available in the below mentioned link. This is for your reference.

http://spark.apache.org/docs/latest/streaming-programming-guide.html

