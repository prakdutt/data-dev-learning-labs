# Network Data Ingestion and Transformation

A data collection server, shown in the diagram below, is collecting data in real time from the local network. The data collected by the Server is working with a Client residing in DLP to transfer the network data collected through Kafka. Using Kafka socket code, we are making a connection to the client and capture the network data and send it to a Kafka topic created. From this topic, data will be moved to HDFS by a Consumer program. With the data present in HDFS, we can then further transform it by running the program we created, visualize the data before and after the transformation in different chart format such as pie chart, bar chart etc. using Tableau. The diagram shows how exactly network data flows from a local network through Kafka in HDFS and gets transformed. 

![alt tag](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/net-data-ingest-trans/assets/images/flow1.png?raw=true)

In this lab, the network stream will be pre-created, so it will be available live in the platform for access. The steps for creating a network stream is as follows, but a user doesnâ€™t need to operate these to create a stream. 


# Lab Objectives

*	Show how ingest a network stream in DevNet data platform
*	Show how to get network data from the HDFS. 
*	Learn to transform network data by creating a transform function using IDE
* Learn how to save a file to HDFS and visualize data

# Prerequisites

*	Knowledge on Hadoop to store the network data.
*	Studied platform user guide.
*	Basic knowledge of how spark works.
*	Use of Chrome OS

# Lab Settings

"Data Repository" section is allowing you to create network real-time data stream. Kafka's producer will push the Network traffic generated data to Kafka cluster and Consumer will consume that data and save that into HDFS in real-time.
From HDFS, we can visualize the data using visualization tool. This application will allow you to use the existing Kafka's Producer & Consumer function to ingest your real time network data into HDFS environment.

N.B: You can select the pre-loaded network data for the process with pre-seleted Kafka and Network traffic generated server.  DLP platform provide a default Kafka's Producer, Consumer and network traffic generator. User can defined and deploy their own service also.

# Step 1: Explore DLP Devevelopment Hub

DLP website URL ([link](https://developer.cisco.com/))

[http://10.10.10.74/DDPDevUI/demo/#/ddp/login]

1. Go to Data Repository to browse data source
1. Go to the development area by clicking Development Hub.
1. Then create a new workspace as per the options available. whether you need Spark Java or Spark Scala, etc. (select Spark Java)
1. Select the workspace you created, Launch IDE by clicking the Launch link.

Select Workspace from "Development Hub". The pre-defined workspace is "wksp-transform"
![alk-tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/net-data-ingest-trans/assets/images/workspaceselection.PNG?raw=true)
