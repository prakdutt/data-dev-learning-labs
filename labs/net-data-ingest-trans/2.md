# Step 2: Developing code in IDE
1. Go to Workspace to put your code (sample code in code-section) here.

![alt tag](https://github.com/CiscoDevNet/data-dev-learning-labs/blob/master/labs/net-data-ingest-trans/assets/images/ide1.png?raw=true)

1. Compile and build it. Click run button, then check the build result.

![alt tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/net-data-ingest-trans/assets/images/build.png?raw=true)

# Step 3: Run the Program
1)	Double click run.sh to open it, change parameters as you wanted
![alt tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/net-data-ingest-trans/assets/images/runProgram.png?raw=true)

USER: your current login user name
INPUT: The file name in “Data Repository” that you want transform
OUTPUT: The output file name that your code will generate.

2)	Choose a Command run under Edit Commands, then click the blue button 
![alt tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/net-data-ingest-trans/assets/images/runbutton.png?raw=true) to run, as in the Terminal.
![alt tag](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/net-data-ingest-trans/assets/images/runProgram.png?raw=true)


1. cd target to view the package
1. Enter the command below to run your job
`HADOOP_USER_NAME=dev_1 spark-submit –master yarn –deploy-mode cluster –class TransformData /projects/spark-transform/target/transform-0.0.1-SNAPSHOT-jar-with-depencies.jar parameter1 parameter2 parameter3`

`parameter1`: the data file on the hdfs we need to transform.
`parameter2`: the path of the output; a folder will be created automatically after the job is done.
`parameter3`: the name of the output file.

Example:

![Example](https://github.com/prakdutt/data-dev-learning-labs/blob/master/labs/net-data-ingest-trans/assets/images/output1.png?raw=true)
